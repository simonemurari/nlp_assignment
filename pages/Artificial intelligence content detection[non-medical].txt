Artificial intelligence detection software aims to determine whether some content (text, image, video or audio) was generated using artificial intelligence (AI).    
As of 2023, the main examples of this are software like GPTZero, which claims to detect if text has been created by artificial intelligence and is sometimes used in colleges and universities to prevent student plagiarism. However, the reliability of such software is a topic of debate, and there are concerns about the potential misapplication of AI detection software by educators.

Text detection
For text, this is usually done to prevent alleged plagiarism, often by detecting repetition of words as telltale signs that a text was AI-generated (including AI hallucinations). They are often used by teachers marking their students, usually on an ad hoc basis. Following the release of ChatGPT and similar AI text generative software, many educational establishments have issued policies against the use of AI by students. AI text detection software is also used by those assessing job applicants, as well as online search engines.Current detectors may sometimes be unreliable and have incorrectly marked work by humans as originating from AI while failing to detect AI-generated work in other instances. MIT Technology Review said that the technology "struggled to pick up ChatGPT-generated text that had been slightly rearranged by humans and obfuscated by a paraphrasing tool". AI text detection software has also been shown to discriminate against non-native speakers of English.Two students from the University of California, Davis, nearly faced expulsion after their professors scanned their essays with a text detection tool called Turnitin which flagged the essays as having been generated by AI. However, following media coverage, and a thorough investigation, the students were cleared of any wrongdoing.In April 2023, Cambridge University and other members of the Russell Group of universities in the United Kingdom opted out of Turnitin's AI text detection tool, after expressing concerns it was unreliable. The University of Texas at Austin opted out of the system six months later.In May 2023, a professor at Texas A&M University–Commerce used ChatGPT to detect whether his students' content was written by it, which ChatGPT said was the case. As such, he threatened to fail the class despite ChatGPT not being able to detect AI-generated writing. No students were prevented from graduating because of the issue, and all but one student (who admitted to using the software) were exonerated from accusations of having used ChatGPT in their content.

Anti text detection
There is software available designed to bypass AI text detection. In August 2023, a study was conducted by Taloni, et al. at Magna Græcia University, to test AI text detection. The study tested an AI detection tool called Originality.ai, and found it detected GPT-4 with a mean accuracy of 91.3%. 
However, the tests noted that when GPT-4 texts were processed through Undetectable.ai (a tool designed to bypass text detection),  the AI detector's accuracy significantly dropped to 27.8%. The study results were published in the Eye Journal on Nature.com, and ResearchGate.Some experts also believe that techniques like digital watermarking are ineffective because they can be removed or added to trigger false positives.

Image, video and audio detection
A number of purported AI image detection software exists, to detect AI-generated images (for example, those originating from Midjourney or DALL-E). They are not completely reliable. Others claim to identify video and audio deepfakes, but this technology is also not fully reliable yet either. Despite debate around the efficacy of watermarking, Google DeepMind is actively developing a detection software called SynthID, which works by inserting a digital watermark that is invisible to the human eye into the pixels of an image.

See also
AI alignment
Content similarity detection
Hallucination (artificial intelligence)
Natural language processing


== References ==